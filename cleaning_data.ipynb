{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "General Statistics from The World Bank DataBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fcac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef41168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "factors = pd.read_csv(\"../climate_final/factors.csv\")    #gdp, population, imports, exports\n",
    "countries = pd.read_csv(\"../climate_final/countries.csv\")    #country info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove aggregates from countries df\n",
    "countries = countries[countries.Region != 'Aggregates']\n",
    "#select columns of interest in countries df\n",
    "countries_reduced = countries[[\"Country code\", \"Country name\", \"Region\"]]\n",
    "#rename country name in countries df to accomplish merge\n",
    "countries_renamed = countries_reduced.rename(columns={\"Country name\":\"Country Name\"})\n",
    "#delete country code and time code column froms factors df\n",
    "factors_reduced = factors.drop(columns=[\"Country Code\", \"Time Code\"])\n",
    "#merge datasets on country name\n",
    "data = pd.merge(countries_renamed, factors_reduced, on=\"Country Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "data_renamed = data.rename(columns={'Country code': 'iso', \n",
    "                                    'Country Name': 'country', \n",
    "                                    'Region': 'region', \n",
    "                                    'Time': 'year', \n",
    "                                    'Time Code': 'year_code',\n",
    "       'Population, total [SP.POP.TOTL]': 'pop_total',\n",
    "       'Population growth (annual %) [SP.POP.GROW]': 'pop_growth',\n",
    "       'GDP (constant 2010 US$) [NY.GDP.MKTP.KD]': 'gdp',\n",
    "       'Imports of goods and services (constant 2010 US$) [NE.IMP.GNFS.KD]':'imports',\n",
    "       'Exports of goods and services (current US$) [NE.EXP.GNFS.CD]':'exports',\n",
    "       'Average precipitation in depth (mm per year) [AG.LND.PRCP.MM]':'avg_precip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea41f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use numpy na to remove empty rows\n",
    "data_renamed[\"iso\"].replace('nan', np.nan, inplace=True)\n",
    "data_renamed[\"iso\"].replace('NaN', np.nan, inplace=True)\n",
    "data_renamed.dropna(axis=0, subset=['iso'], inplace=True)\n",
    "#replace '..' with numpy na\n",
    "data_renamed.replace('..', np.nan, inplace=True)\n",
    "#make copy with clean name\n",
    "factors = data_renamed.copy()\n",
    "#make sure year column is numeric\n",
    "factors['year'] = factors['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d22e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b17ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "emissions_csv = pd.read_csv(\"../climate_final/emissions.csv\")    #emissions of GHGs by country\n",
    "#reduce emissions dataset to data of interest\n",
    "##columns\n",
    "emissions_subset = emissions_csv[['iso_code', 'country', 'year', 'co2', 'methane', \n",
    "                                  'nitrous_oxide', 'total_ghg']]\n",
    "##years\n",
    "emissions_reduced = emissions_subset[emissions_subset['year']>=2000]\n",
    "##renamed iso_code to iso\n",
    "emissions_reduced = emissions_reduced.rename(columns={'iso_code':'iso'})\n",
    "##make copy with clean name\n",
    "emissions = emissions_reduced.copy()\n",
    "emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce002bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Emissions Data - Our World in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af828f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "emissions_csv = pd.read_csv(\"../climate_final/emissions.csv\")    #emissions of GHGs by country\n",
    "#reduce emissions dataset to data of interest\n",
    "##columns\n",
    "emissions_subset = emissions_csv[['iso_code', 'country', 'year', 'co2', 'methane', \n",
    "                                  'nitrous_oxide', 'total_ghg']]\n",
    "##years\n",
    "emissions_reduced = emissions_subset[emissions_subset['year']>=2000]\n",
    "##renamed iso_code to iso\n",
    "emissions_reduced = emissions_reduced.rename(columns={'iso_code':'iso'})\n",
    "##make copy with clean name\n",
    "emissions = emissions_reduced.copy()\n",
    "emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extreme Weather Information - EM-DAT International Disaster Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "disasters_csv = pd.read_csv(\"../climate_final/disasters.csv\")    #database of occurences of natural disasters\n",
    "#reduce disasters dataset to columns of interest\n",
    "##columns\n",
    "disasters_subset = disasters_csv[['Year','Country', 'ISO', 'Region', 'Continent', \n",
    "                                  'Disaster Group', 'Disaster Subgroup', 'Disaster Type', \n",
    "                                  'Disaster Subtype', 'Disaster Subsubtype','Total Deaths', \n",
    "                                  'Total Affected', 'Latitude', 'Longitude']]\n",
    "##years of interest\n",
    "disasters_reduced = disasters_subset[disasters_subset['Year']>=2000]\n",
    "##make column names lowercase\n",
    "disasters_reduced = disasters_reduced.rename(columns=str.lower)\n",
    "##make copy with clean name\n",
    "disasters = disasters_reduced.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0888d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Temperature Data - Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "temps_bycity_csv = pd.read_csv(\"../climate_final/temps_bycity.csv\")    #land temperatures by city\n",
    "#remove average temperature uncertainty column\n",
    "temps_bycity_reduced = temps_bycity_csv[['dt','AverageTemperature','City', 'Country', \n",
    "                                         'Latitude', 'Longitude']]\n",
    "#rename columns\n",
    "temps_bycity_renamed = temps_bycity_reduced.rename(columns={'dt':'date',\n",
    "                                                       'AverageTemperature': 'avg_temp_c',\n",
    "                                                       'City': 'city',\n",
    "                                                       'Country': 'country',\n",
    "                                                       'Latitude': 'latitude',\n",
    "                                                       'Longitude':'longitude'})\n",
    "#create a temperature column in farenheit\n",
    "temps_bycity_renamed['avg_temp_f'] = [((x*9/5) + 32) for x in temps_bycity_renamed['avg_temp_c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c81a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create year and month columns\n",
    "year_list = []\n",
    "month_list = []\n",
    "#for loop over date column\n",
    "for date in temps_bycity_renamed['date']:\n",
    "    split = date.split(\"-\")\n",
    "    y = pd.to_numeric(split[0])    #get year from string split\n",
    "    m = pd.to_numeric(split[2])    #get month from string split\n",
    "    year_list.append(y)    #append result to year list\n",
    "    month_list.append(m)    #append result to month list\n",
    "#turn lists in columns\n",
    "temps_bycity_renamed['year'] = year_list\n",
    "temps_bycity_renamed['month'] = month_list\n",
    "#reorder columns\n",
    "temps_bycity = temps_bycity_renamed[['year', 'month', 'date', 'city', 'country', \n",
    "                                     'avg_temp_c', 'avg_temp_f', 'latitude', 'longitude']]\n",
    "#select years\n",
    "temps_bycity = temps_bycity[temps_bycity['year']>=2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a dataframe of averaged temps by country\n",
    "country_list = temps_bycity['country'].unique()\n",
    "yr_list = temps_bycity['year'].unique()\n",
    "temps_f_list = []\n",
    "temps_c_list = []\n",
    "country_col = []\n",
    "year_col = []\n",
    "#loop through countries\n",
    "for i in range(len(country_list)):\n",
    "    #loop through years\n",
    "    for j in range(len(yr_list)):\n",
    "        #subset to particular country and year\n",
    "        c = country_list[i]\n",
    "        y = yr_list[j]\n",
    "        subset = temps_bycity[(temps_bycity['country']==c) & (temps_bycity['year']==y)]\n",
    "        #average all temperature readings from that year\n",
    "        avg_f = subset['avg_temp_f'].mean()\n",
    "        avg_c = subset['avg_temp_c'].mean()\n",
    "        #add averages to lists\n",
    "        temps_f_list.append(avg_f)\n",
    "        temps_c_list.append(avg_c)\n",
    "        #add country names and years to lists\n",
    "        country_col.append(c)\n",
    "        year_col.append(y)\n",
    "    \n",
    "#create dataframe\n",
    "temps_bycountry = pd.DataFrame({\"country\": country_col,\n",
    "                                \"year\": year_col,\n",
    "                               \"avg_temp_c\": temps_c_list,\n",
    "                               \"avg_temp_f\": temps_f_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c99132",
   "metadata": {},
   "outputs": [],
   "source": [
    "The last step to merge datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0accc40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes that match each research questions\n",
    "##Question 1\n",
    "q1 = pd.merge(factors, emissions, on=['country','year', 'iso'])\n",
    "q1_df = pd.merge(q1, temps_bycountry, on=['country', 'year'])\n",
    "##Question 2\n",
    "q2_df = pd.merge(emissions, temps_bycountry, on=['country','year'])\n",
    "##Question 3\n",
    "factors_subset = factors[['country', 'region', 'year', 'pop_total', 'pop_growth']]\n",
    "q3_df = pd.merge(factors_subset, temps_bycountry, on=['country','year'])\n",
    "##Question 4\n",
    "factors_subset2 = factors[['country', 'region', 'year', 'avg_precip']]\n",
    "q4 = pd.merge(factors_subset2, temps_bycountry, on=['country', 'year'])\n",
    "q4_df = pd.merge(q4, emissions, on=['country', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.to_csv('../climate_final/emissions_clean.csv', index=False)\n",
    "factors.to_csv('../climate_final/factors_clean.csv', index=False)\n",
    "disasters.to_csv('../climate_final/disasters_clean.csv', index=False)\n",
    "temps_bycity.to_csv('../climate_final/temps_bycity_clean.csv', index=False)\n",
    "temps_bycountry.to_csv('../climate_final/temps_bycountry_clean.csv', index=False)\n",
    "q1_df.to_csv('../climate_final/question1_df.csv', index=False)\n",
    "q2_df.to_csv('../climate_final/question2_df.csv', index=False)\n",
    "q3_df.to_csv('../climate_final/question3_df.csv', index=False)\n",
    "q4_df.to_csv('..climate_final/question4_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
